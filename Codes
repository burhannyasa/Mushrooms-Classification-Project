ALL CODES



import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt


from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.svm import LinearSVC, NuSVC, SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, SGDClassifier
from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier
from yellowbrick.classifier import ClassificationReport
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.cluster import KMeans
 
df=pd.read_csv("mushrooms.csv")
df.head()
df.info()
df.dtypes
df.isna().sum()
df.describe()
plt.figure(figsize=(16, 20))
for i, column in enumerate(df.columns[1:], 1):
    plt.subplot(6, 4, i)
    sns.countplot(x=column, data=df, palette="viridis")
    plt.title(f"{column} Countplot")
    plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
categorical_counts = df.apply(lambda col: col.value_counts().shape[0])
 
# Sütun grafiği oluşturalım
plt.figure(figsize=(10, 6))
categorical_counts.plot(kind='bar', color='skyblue')
plt.title('Her Sütundaki Kategorik Değişkenlerin Sayısı')
plt.xlabel('Sütunlar')
plt.ylabel('Değer Sayısı')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
def cramers_v_matrix(data):
    categorical_vars = data.select_dtypes(include=['object', 'category']).columns
    n_vars = len(categorical_vars)
    matrix = np.zeros((n_vars, n_vars))
    
    for i, var1 in enumerate(categorical_vars):
        for j, var2 in enumerate(categorical_vars):
            if i <= j:
                confusion_matrix = pd.crosstab(data[var1], data[var2])
                chi2 = chi2_contingency(confusion_matrix)[0]
                n = confusion_matrix.sum().sum()
                phi2 = chi2 / n
                r, k = confusion_matrix.shape
                phi2corr = max(0, phi2 - ((k - 1) * (r - 1)) / (n - 1))
                rcorr = r - ((r - 1) ** 2) / (n - 1)
                kcorr = k - ((k - 1) ** 2) / (n - 1)
                matrix[i, j] = np.sqrt(phi2corr / min((kcorr - 1), (rcorr - 1)))
                matrix[j, i] = matrix[i, j]
    
    return pd.DataFrame(matrix, index=categorical_vars, columns=categorical_vars)
 
# Örnek kullanım
# Veri setiniz 'data' adlı bir DataFrame ise:
# data = pd.read_csv("veri.csv")
cramer_v_results = cramers_v_matrix(df)
plt.figure(figsize=(10, 8))
sns.heatmap(cramer_v_results, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Cramer's V Skorları Heatmap")
plt.xlabel("Değişkenler")
plt.ylabel("Değişkenler")
plt.show()
# Grafikleri yan yana sığdırmak için subplotlar oluşturalım
fig, axes = plt.subplots(nrows=6, ncols=4, figsize=(20, 20))
 
# Her bir değişken için gruplanmış verileri çizelim
for i, ax in enumerate(axes.flatten()):
    if i < len(df.columns):
        grouped = df.groupby([df.columns[i], 'class']).size().unstack(fill_value=0)
        colors = ["#DA70D6", "#778899"]
        grouped.plot(kind='bar', color=colors, stacked=True, ax=ax)
        ax.set_title('{}'.format(df.columns[i]))
        ax.set_xlabel('')
        ax.set_ylabel('Count')
        ax.legend(title='Class')
 
# Eksenlerin üst üste gelmemesi için layout ayarlayalım
plt.tight_layout()
plt.show()
grouped = df.groupby(['odor', 'spore-print-color', 'gill-color','class']).size().unstack(fill_value=0)
colors = ["#DA70D6", "#778899"]
 
grouped.plot(kind='bar',color=colors, stacked=True)
plt.title('High Correlation Variables According Class')
plt.xlabel('Habitat and Population')
plt.ylabel('Count')
plt.xticks([])  # X ekseni etiketlerini kaldırma
plt.legend(title='Class')
plt.show()
from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
df = df.apply(label_encoder.fit_transform)
X = df.drop('class', axis=1)  # 'class' sütununu hedef değişken olarak kabul ediyoruz
y = df['class']
models = [
    SVC(gamma='auto'), NuSVC(gamma='auto'), LinearSVC(),
    SGDClassifier(max_iter=100, tol=1e-3), KNeighborsClassifier(),
    LogisticRegression(solver='lbfgs'), LogisticRegressionCV(cv=3),
    BaggingClassifier(), ExtraTreesClassifier(n_estimators=300),
    RandomForestClassifier(n_estimators=300)
]
 
 
def score_model(X, y, estimator, **kwargs):
    """
    Test various estimators.
    """
    y = LabelEncoder().fit_transform(y)
    model = Pipeline([
        ('one_hot_encoder', OneHotEncoder()),
        ('estimator', estimator)
    ])
 
    # Instantiate the classification model and visualizer
    model.fit(X, y, **kwargs)
 
    expected  = y
    predicted = model.predict(X)
 
    # Compute and return F1 (harmonic mean of precision and recall)
    print("{}: {}".format(estimator.__class__.__name__, f1_score(expected, predicted)))
 
for model in models:
    score_model(X, y, model)

models = [
    ("SVC", SVC()),
    ("NuSVC", NuSVC()),
    ("LinearSVC", LinearSVC()),
    ("SGDClassifier", SGDClassifier()),
    ("KNeighborsClassifier", KNeighborsClassifier()),
    ("LogisticRegression", LogisticRegression()),
    ("LogisticRegressionCV", LogisticRegressionCV(cv=3)),
    ("BaggingClassifier", BaggingClassifier()),
    ("ExtraTreesClassifier", ExtraTreesClassifier()),
    ("RandomForestClassifier", RandomForestClassifier())
]
 
# Modelleri değerlendir ve çapraz doğrulama skorlarını topla
cv_results = []
model_names = []
for name, model in models:
    scores = cross_val_score(model, X, y, scoring='f1', cv=5)
    cv_results.extend(scores)
    model_names.extend([name] * len(scores))
 
# Skorları içeren bir veri çerçevesi oluştur
df_scores = pd.DataFrame({"Model": model_names, "F1 Score": cv_results})
 
# Kutu grafiğiyle görselleştir
plt.figure(figsize=(12, 6))
sns.boxplot(data=df_scores, x="Model", y="F1 Score")
plt.title('Cross-Validation F1 Scores of Classification Models')
plt.xlabel('Classification Models')
plt.ylabel('F1 Score')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
from sklearn.model_selection import cross_val_score
 
models = [
    ("SVC", SVC()),
    ("NuSVC", NuSVC()),
    ("LinearSVC", LinearSVC()),
    ("SGDClassifier", SGDClassifier()),
    ("KNeighborsClassifier", KNeighborsClassifier()),
    ("LogisticRegression", LogisticRegression()),
    ("LogisticRegressionCV", LogisticRegressionCV(cv=3)),
    ("BaggingClassifier", BaggingClassifier()),
    ("ExtraTreesClassifier", ExtraTreesClassifier()),
    ("RandomForestClassifier", RandomForestClassifier())
]
 
# Modelleri değerlendir ve çapraz doğrulama skorlarını topla
cv_results = []
model_names = []
for name, model in models:
    scores = cross_val_score(model, X, y, scoring='accuracy', cv=5)
    cv_results.extend(scores)
    model_names.extend([name] * len(scores))
 
# Skorları içeren bir veri çerçevesi oluştur
df_scores = pd.DataFrame({"Model": model_names, "Accuracy": cv_results})
 
# Kutu grafiğiyle görselleştir
plt.figure(figsize=(12, 6))
sns.boxplot(data=df_scores, x="Model", y="Accuracy")
plt.title('Cross-Validation Accuracy Scores of Classification Models')
plt.xlabel('Classification Models')
plt.ylabel('Accuracy')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
from sklearn.model_selection import cross_val_score
from sklearn.neighbors import KNeighborsClassifier
 
# KNN sınıflandırıcıyı oluşturma
knn = KNeighborsClassifier(n_neighbors=5)
 
# Çapraz doğrulama yapma
scores = cross_val_score(knn, X, y, cv=5)  # cv parametresi K için kullanılacak kat sayıyı belirtir
 
# Sonuçları görüntüleme
print("Çapraz Doğrulama Skorları:", scores)
print("Ortalama Doğruluk:", scores.mean())
from sklearn.model_selection import GridSearchCV
param_grid = {
    'n_neighbors': range(1, 20),  # Komşu sayısı
    'weights': ['uniform', 'distance'],  # Ağırlık fonksiyonu
    'metric': ['euclidean', 'manhattan', 'chebyshev']  # Mesafe metriği
}
 
# Grid arama ile hiperparametre optimizasyonu yapma
grid_search = GridSearchCV(knn, param_grid, cv=5)
grid_search.fit(X, y)
 
# En iyi hiperparametreleri ve en iyi skoru görüntüleme
print("En İyi Hiperparametreler:", grid_search.best_params_)
print("En İyi Skor:", grid_search.best_score_)
from sklearn.model_selection import cross_val_score
from sklearn.neighbors import KNeighborsClassifier
 
# KNN sınıflandırıcıyı oluşturma
knn = KNeighborsClassifier(n_neighbors=2,metric="manhattan",weights="uniform")
 
# Çapraz doğrulama yapma
scores = cross_val_score(knn, X, y, cv=5)  # cv parametresi K için kullanılacak kat sayıyı belirtir
 
# Sonuçları görüntüleme
print("Çapraz Doğrulama Skorları:", scores)
print("Ortalama Doğruluk:", scores.mean())
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)
 
# Logistic Regresyon modelini oluştur ve eğit
log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)
 
# Test seti üzerinde modelin performansını değerlendir
y_pred = log_reg.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
cv_scores = cross_val_score(log_reg, X, y, cv=5)  # 5 katlı cross-validation
print("Cross-Validation Scores:", cv_scores)
print("Mean CV Score:", cv_scores.mean())
from sklearn.model_selection import GridSearchCV
 
# Grid Search için parametrelerin belirlenmesi
param_grid = {'C': [0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}
 
# Grid Search ile Logistic Regresyon modelini optimize et
grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)
grid_search.fit(X_train, y_train)
 
# En iyi parametreleri ve en iyi skoru yazdır
print("Best Parameters:", grid_search.best_params_)
print("Best Score:", grid_search.best_score_)
log_reg.fit(X_train, y_train)
 
 
coefficients = log_reg.coef_[0]
 
feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': np.abs(coefficients)})
feature_importance = feature_importance.sort_values('Importance', ascending=True)
feature_importance.plot(x='Feature', y='Importance', kind='barh', figsize=(10, 6))
X_log=df[["gill-size","gill-spacing","veil-color","stalk-surface-above-ring","stalk-root","ring-type"]]
X_train, X_test, y_train, y_test = train_test_split(X_log, y, test_size=0.2, random_state=21)
 
# Logistic Regresyon modelini oluştur ve eğit
log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)
 
# Test seti üzerinde modelin performansını değerlendir
y_pred = log_reg.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
cv_scores = cross_val_score(log_reg, X_log, y, cv=5)  # 5 katlı cross-validation
print("Cross-Validation Scores:", cv_scores)
print("Mean CV Score:", cv_scores.mean())
# Grid Search için parametrelerin belirlenmesi
param_grid = {'C': [0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}
 
# Grid Search ile Logistic Regresyon modelini optimize et
grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)
grid_search.fit(X_train, y_train)
 
# En iyi parametreleri ve en iyi skoru yazdır
print("Best Parameters:", grid_search.best_params_)
print("Best Score:", grid_search.best_score_)
cv_scores = cross_val_score(LogisticRegression(C= 10, penalty='l2'), X_log, y, cv=5)  # 5 katlı cross-validation
print("Cross-Validation Scores:", cv_scores)
print("Mean CV Score:", cv_scores.mean())
log_reg = LogisticRegression(C= 10, penalty='l2')
log_reg.fit(X_train, y_train)
 
# Test seti üzerinde tahmin yap
y_pred_proba = log_reg.predict_proba(X_test)[:,1]  # Sadece pozitif sınıfın olasılıklarını al
 
# ROC eğrisini çizdir
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
plt.plot(fpr, tpr)
plt.plot([0, 1], [0, 1], '--', color='gray')  # Rastgele tahmin çizgisi
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.show()
 
# ROC AUC skorunu hesapla
roc_auc = roc_auc_score(y_test, y_pred_proba)
print("ROC AUC Score:", roc_auc)
cv = StratifiedKFold(5)
visualizer = RFECV(RandomForestClassifier(), cv=cv, scoring='accuracy')
 
visualizer.fit(X, y)    
visualizer.show()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model=RandomForestClassifier(n_estimators=100, random_state=42)
sfs = SFS(model,
          k_features=3,
          forward=True,
          floating=False,
          scoring='accuracy',
          cv=5)
 
sfs.fit(X_train, y_train)
selected_features_idx = sfs.k_feature_idx_
selected_features_names = X.columns[list(selected_features_idx)]
print("En iyi 3 özellik:", selected_features_names)
from sklearn.model_selection import GridSearchCV
 
# Hiperparametre aralıkları
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}
 
# GridSearchCV kullanarak optimizasyon
rf = RandomForestClassifier(random_state=42)
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='accuracy')
grid_search.fit(X_train, y_train)
 
print("En iyi parametreler:", grid_search.best_params_)
print("En iyi doğruluk:", grid_search.best_score_)

X=df[['cap-color', 'odor', 'spore-print-color']]
y=df["class"]
# Create a cross-validation strategy
cv = StratifiedKFold(n_splits=12, shuffle=True, random_state=42)
visualizer = CVScores(RandomForestClassifier(max_depth= None, min_samples_leaf= 1, min_samples_split= 2, n_estimators= 50), cv=cv, scoring='f1_weighted')
 
visualizer.fit(X, y)        
visualizer.show()  
selected_features = ['cap-color', 'odor', 'spore-print-color']
X_selected = df[selected_features]
y = df['class']
 
# One-hot encoding ile veriyi işleme
X_encoded = pd.get_dummies(X_selected)
 
# Eğitim ve test veri setlerini ayırma
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)
 
# Tek bir ağaç oluşturma ve eğitme
single_tree_model = DecisionTreeClassifier(random_state=42)
single_tree_model.fit(X_train, y_train)
 
# Karar ağacını çizme
# Karar ağacını çizme
plt.figure(figsize=(15, 10))
plot_tree(single_tree_model, feature_names=X_encoded.columns, class_names=y.unique().astype(str), filled=True)
plt.show()
from yellowbrick.classifier import ClassificationReport
pipeline = Pipeline([
    ('estimator', model)
])
 
# Create the classification report visualizer
visualizer = ClassificationReport(
    pipeline, classes=['edible', 'poisonous'], cmap="YlGn", size=(600, 360)
)
 
# Fit the visualizer and generate the classification report
visualizer.fit(X_train, y_train)
visualizer.score(X_test, y_test)
 
# Display the visualizer
visualizer.show()
X = df.drop('class', axis=1)
y = df['class']
 
# K-means modelini oluşturma ve eğitme
kmeans = KMeans(n_clusters=2, random_state=42)
kmeans.fit(X)
 
# PCA ile boyut indirgeme
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)
 
# Küme merkezlerini ve küme etiketlerini alarak görselleştirme
plt.figure(figsize=(10, 6))
 
for i in range(2):
    plt.scatter(X_pca[kmeans.labels_ == i, 0], X_pca[kmeans.labels_ == i, 1], label=f'Cluster {i}')
 
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red', label='Centroids')
plt.title('K-means Clustering with PCA Visualization')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.legend()
plt.show()
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
 
# PCA modelini oluşturma ve uygulama
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)
 
# Sınıflara göre renklendirilmiş scatter plot çizimi
plt.figure(figsize=(10, 8))
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', alpha=0.5)
plt.title('PCA ile Sınıflara Göre Veri Görselleştirme')
plt.xlabel('1. Bileşen')
plt.ylabel('2. Bileşen')
plt.colorbar(label='Sınıf')
plt.grid(True)
plt.show()
import matplotlib.pyplot as plt
import numpy as np
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
 
k_values = range(2, 11)  # 2'den 10'a kadar küme sayılarını deneyin
 
# Her bir küme sayısı için Silhouette skorunu hesaplayın
silhouette_scores = []
for k in k_values:
    kmeans = KMeans(n_clusters=k, random_state=42)
    cluster_labels = kmeans.fit_predict(X)
    silhouette_avg = silhouette_score(X, cluster_labels)
    silhouette_scores.append(silhouette_avg)
 
# Silhouette skorlarını görselleştirin
plt.figure(figsize=(10, 6))
plt.bar(k_values, silhouette_scores)
plt.xlabel('Küme Sayısı (k)')
plt.ylabel('Silhouette Skoru')
plt.title('K-Means için Silhouette Skoru Değerlendirmesi')
plt.xticks(np.arange(min(k_values), max(k_values)+1, 1))
plt.show()
